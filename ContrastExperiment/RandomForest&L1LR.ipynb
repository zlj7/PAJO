{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgjD8JZV-X-3",
        "outputId": "e5c9db82-a0bc-4644-87cd-606ae2ab4736"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jiHs3gqoBes7",
        "outputId": "69d144a6-d504-414b-a8f1-eafe3cb51e01"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.16.2-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.5/268.5 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.6.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.16.2 safetensors-0.3.1 tokenizers-0.13.3 transformers-4.30.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def shuffle_dataset(data_X,data_Y):\n",
        "    length = len(data_X)\n",
        "    rng = np.random.default_rng(12345)\n",
        "    index = np.arange(length)\n",
        "    print(index)\n",
        "    rng.shuffle(index)\n",
        "    print(index)\n",
        "    return data_X[index],data_Y[index]"
      ],
      "metadata": {
        "id": "jiIxJvuHRihO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "title_0_embed = np.load('/content/drive/MyDrive/neckpain_vector/title0_embed.npy')\n",
        "title_1_embed = np.load('/content/drive/MyDrive/neckpain_vector/title1_embed.npy')\n",
        "abstruct_0_embed = np.load('/content/drive/MyDrive/neckpain_vector/abstract0_embed.npy')\n",
        "abstruct_1_embed = np.load('/content/drive/MyDrive/neckpain_vector/abstract1_embed.npy')\n",
        "X_0 = pd.read_excel('/content/drive/MyDrive/neckpain_data/X_0.xlsx')\n",
        "X_1 = pd.read_excel('/content/drive/MyDrive/neckpain_data/X_1.xlsx')\n",
        "Y_0 = pd.read_excel('/content/drive/MyDrive/neckpain_data/Y_0.xlsx').values\n",
        "Y_1 = pd.read_excel('/content/drive/MyDrive/neckpain_data/Y_1.xlsx').values\n",
        "\n",
        "title_0 = pd.DataFrame(title_0_embed)\n",
        "title_1 = pd.DataFrame(title_1_embed)\n",
        "abstruct_0 = pd.DataFrame(abstruct_0_embed)\n",
        "abstruct_1 = pd.DataFrame(abstruct_1_embed)\n",
        "\n",
        "feature = pd.concat([X_0,title_0], axis=1)\n",
        "feature_0 = pd.concat([feature,abstruct_0], axis=1).values\n",
        "feature = pd.concat([X_1,title_1], axis=1)\n",
        "feature_1 = pd.concat([feature,abstruct_1], axis=1).values\n",
        "\n",
        "rs = np.random.RandomState(42)\n",
        "L = list(rs.randint(0, len(X_0), int(7/3*len(X_1))))\n",
        "feature_0 = feature_0[L]\n",
        "Y_0 = Y_0[L]\n",
        "\n",
        "train_X_0, test_X_0, train_Y_0, test_Y_0 = train_test_split(feature_0, Y_0, train_size=0.80, random_state=42)\n",
        "train_X_1, test_X_1, train_Y_1, test_Y_1 = train_test_split(feature_1, Y_1, train_size=0.80, random_state=42)\n",
        "\n",
        "train_Y_0 = train_Y_0.reshape(len(train_Y_0),1)\n",
        "train_Y_1 = train_Y_1.reshape(len(train_Y_1),1)\n",
        "test_Y_0 = test_Y_0.reshape(len(test_Y_0),1)\n",
        "test_Y_1 = test_Y_1.reshape(len(test_Y_1),1)\n",
        "\n",
        "train_X = np.vstack((train_X_0,train_X_1))\n",
        "train_Y = np.vstack((train_Y_0,train_Y_1))\n",
        "test_X = np.vstack((test_X_0,test_X_1))\n",
        "test_Y = np.vstack((test_Y_0,test_Y_1))\n",
        "\n",
        "train_X_input,train_Y_input = shuffle_dataset(train_X,train_Y)\n",
        "test_X_input,test_Y_input = shuffle_dataset(test_X,test_Y)"
      ],
      "metadata": {
        "id": "aAeh94_D-cnm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ddd2442-9f78-4302-b7d0-b690f8565be9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[   0    1    2 ... 2677 2678 2679]\n",
            "[ 347 1822  200 ... 1246  397  413]\n",
            "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
            " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
            " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
            " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
            " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
            " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
            " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
            " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
            " 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n",
            " 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n",
            " 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287\n",
            " 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n",
            " 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323\n",
            " 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341\n",
            " 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359\n",
            " 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377\n",
            " 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395\n",
            " 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413\n",
            " 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431\n",
            " 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449\n",
            " 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467\n",
            " 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485\n",
            " 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503\n",
            " 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521\n",
            " 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539\n",
            " 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557\n",
            " 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575\n",
            " 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593\n",
            " 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611\n",
            " 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629\n",
            " 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647\n",
            " 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665\n",
            " 666 667 668 669]\n",
            "[125 181 650 550 296 651 422 393 229 203 377 110 231 108  29 376 191 469\n",
            " 120 647 271 503  44 105 283  36 437  31 580 406  51  92 205 188 615  59\n",
            " 343 326 487 546 308 328 255 103 250   6 597 474 141 416  35 500 453 291\n",
            " 571 657 659 134 411 633 595 300 477 178 157 649  91 217 408  96 354 256\n",
            " 667 665 140 512  13 577 202 541 530 612 282 359   2 522 467 119 336 444\n",
            " 194  41  64 243 201 466 409 137 186 613 267 251 228  23 304 600 616 510\n",
            " 473 563 384 371 608  49 454 132 305 588 483  89 279 490 315 187 159 248\n",
            " 124  79 617 117 372  66 618 154 238 353  17 260 658 480 240 502 520 357\n",
            " 139 399 404 258 190 455 652 179   1 468 363   0 414 158 109 623 153 298\n",
            " 516 292 236 303 648 524 174 102 433 622 331 402 277 656 611 131 284 261\n",
            " 415 151 295 602 262 123 346 429 446 543 478 361 662 392 637  56 373 630\n",
            "  90 509 493   7 314  57 313 388 572 529 458  69 200 324 176 391  80 127\n",
            " 307 233 175 506  65 348  99 499 447 234 196 350  50 129 505 599 136 317\n",
            " 338 488 631 316 498 632 138 583 605  82 387 111 150 558 436 211 448 147\n",
            " 244 589 362  27 118 226 169 280  53 441 574 114 646 513 288 489  70 542\n",
            " 425 342 322 551 639 347 438  71 420 163 593 594  55 214 349 306 544 301\n",
            " 629 161 556 626 133 508 423 293 128 497 461 106 168 410  63 645 165 107\n",
            "  81 559  68  38 213 644 560 268 549 332 475 287 552 355 395 511 224 230\n",
            " 514 198   5 246 208 449 325 144 561 663 239 407 327 155 207 121  62 643\n",
            " 241 628 573 215 417 366 619 554 379 504 116  67 242 365 227 204  72 463\n",
            " 476 323  87  45 378 368 206  77 340 661 621 548 653 585 495  37 576 586\n",
            "  78 431 424  16 302  74 285 312  34 135 171 418  60  47 177  48 221 197\n",
            " 457 381 270 299 545 640  54 519  93 570 445 515  15  88 281 460 427 185\n",
            "  46 386 374 666 382 160 356   8 624 167 538 235 421 491 470 486 254 276\n",
            "  11 318  26 113  83 419 170 184 592 582 172 565 569  14 143 555 266  58\n",
            "  25 604 225 182 100  40  52 320 358 642 209 553 183 385 115 531 297 492\n",
            " 329 383  39  95 265 311  32 335 564 257 310 528 641 432 290 562 471 396\n",
            " 625 352 220 635 210 501 164 269 494 464 173 259  61 482 369  28 435 575\n",
            " 481 400 152 112 162 535 145 609 596 601  30 345 581 442 527 590  86 394\n",
            " 398 390 591 578  19  24 664 218 536 309 518 341   9  33 122 216 212 660\n",
            " 654 405 539 496  75 459 540 249  73 273 189 462 232 568 430 337 412 533\n",
            " 401 525 334 634  21  20 367 636 104 485  98 275 294 319  22 428 603 263\n",
            " 142 526 149  76 465 507 146  42 333 403 534 532 339 434 443 584 344 610\n",
            " 627  84 289   3 286 321 380 638 195  94 252  12 479 620 148 567 199 126\n",
            " 606 180 364 247 330 156 426 245 521 101 452 351 166 193 264  85 370 523\n",
            " 456 389 566 668  43 219 253 472 440 484 237 547 517 579 598 439 192  18\n",
            " 450 451   4 614 278 274  97 587  10 655 223 537 375 557 607 669 360 272\n",
            " 130 222 397 413]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install thop\n",
        "!pip install torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mVqljYKQSHn",
        "outputId": "fd3938db-55ce-4525-d523-58bfc8c93636"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: thop in /usr/local/lib/python3.10/dist-packages (0.1.1.post2209072238)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from thop) (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->thop) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->thop) (4.6.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->thop) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->thop) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->thop) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->thop) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->thop) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->thop) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->thop) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->thop) (1.3.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.6.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LassoCV, Lasso\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, roc_auc_score, confusion_matrix\n",
        "import warnings\n",
        "import time\n",
        "import thop\n",
        "from torch.profiler import profile, record_function, ProfilerActivity\n",
        "import torch\n",
        "\n",
        "warnings.filterwarnings(action = 'ignore')\n",
        "\n",
        "Lambdas = np.logspace(-5,2,200)\n",
        "lasso_cv = LassoCV(alphas=Lambdas, cv=5, max_iter=5000)\n",
        "lasso_cv.fit(train_X_input,train_Y_input)\n",
        "lasso = Lasso(alpha=lasso_cv.alpha_, max_iter=10000)\n",
        "\n",
        "start_time = time.time()\n",
        "lasso.fit(train_X_input,train_Y_input)\n",
        "end_time = time.time()\n",
        "\n",
        "# 计算模型的FLOPs和参数数量\n",
        "flops = 2 * train_X_input.shape[1] * train_X_input.shape[0]\n",
        "print(f\"FLOPs: {flops}\")\n",
        "\n",
        "\n",
        "# 计算每秒钟的训练样本数（即MLOPS）\n",
        "num_samples = len(train_X_input)\n",
        "training_time = end_time - start_time\n",
        "samples_per_second = num_samples / training_time\n",
        "\n",
        "y_pred_lasso = lasso.predict(test_X_input)\n",
        "print('lasso AUC = ',metrics.roc_auc_score(test_Y_input,y_pred_lasso))\n",
        "\n",
        "for i in range(y_pred_lasso.size):\n",
        "    if(y_pred_lasso[i] > 0.5):\n",
        "        y_pred_lasso[i] = 1\n",
        "    else:\n",
        "        y_pred_lasso[i] = 0\n",
        "print(metrics.classification_report(y_true=test_Y_input,y_pred= y_pred_lasso, digits=4))\n",
        "tn, fp, fn, tp = confusion_matrix(test_Y_input, y_pred_lasso).ravel()\n",
        "specificity = tn / (tn + fp)\n",
        "sensitivity = tp / (tp + fn)\n",
        "print('Specificity = ', specificity)\n",
        "print('Sensitivity = ', sensitivity)\n",
        "\n",
        "# 输出模型信息\n",
        "print(\"MLOPS: {:.2f}\".format(samples_per_second))"
      ],
      "metadata": {
        "id": "AGxKXIzqgyyf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4155f53d-2f38-4a70-f428-ff7e4bafdeda"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FLOPs: 8318720\n",
            "lasso AUC =  0.8564321250888415\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8189    0.9254    0.8689       469\n",
            "           1     0.7500    0.5224    0.6158       201\n",
            "\n",
            "    accuracy                         0.8045       670\n",
            "   macro avg     0.7844    0.7239    0.7424       670\n",
            "weighted avg     0.7982    0.8045    0.7930       670\n",
            "\n",
            "Specificity =  0.9253731343283582\n",
            "Sensitivity =  0.5223880597014925\n",
            "MLOPS: 54.75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# from sklearn.metrics import f1_score,recall_score,precision_score,accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "# from sklearn.metrics import roc_curve, auc,accuracy_score,precision_recall_curve\n",
        "\n",
        "B = 800\n",
        "n_classes = 2\n",
        "RF = RandomForestClassifier(n_estimators=B,class_weight={0:0.3,1:0.7},\n",
        "                            max_depth=50,bootstrap = True,oob_score=True, max_features='sqrt',random_state=0)\n",
        "start_time = time.time()\n",
        "RF.fit(train_X_input,train_Y_input)\n",
        "end_time = time.time()\n",
        "# 计算每秒钟的训练样本数（即MLOPS）\n",
        "num_samples = len(train_X_input)\n",
        "training_time = end_time - start_time\n",
        "samples_per_second = num_samples / training_time\n",
        "\n",
        "prob = RF.predict_proba(test_X_input)[:,1]\n",
        "print('RandomForest AUC = ',metrics.roc_auc_score(test_Y_input,prob))\n",
        "# 计算单个决策树的FLOPs\n",
        "n_nodes = 2 ** RF.max_depth - 1\n",
        "n_leaves = 2 ** (RF.max_depth - 1)\n",
        "n_features = test_X_input.shape[1]\n",
        "flops_per_tree = (n_features * n_leaves * np.log2(n_leaves) +\n",
        "                  n_leaves * n_classes * (n_classes - 1) +\n",
        "                  n_nodes * n_features * np.log2(n_leaves))\n",
        "\n",
        "# 计算随机森林的FLOPs\n",
        "flops = flops_per_tree * RF.n_estimators\n",
        "print(f\"FLOPs: {flops}\")\n",
        "print(\"MLOPS: {:.2f}\".format(samples_per_second))\n",
        "\n",
        "predict = []\n",
        "for i in range(len(test_Y_input)):\n",
        "  if(prob[i]>0.3):\n",
        "    predict.append(1)\n",
        "  else:\n",
        "    predict.append(0)\n",
        "tn, fp, fn, tp = confusion_matrix(test_Y_input, predict).ravel()\n",
        "specificity = tn / (tn + fp)\n",
        "sensitivity = tp / (tp + fn)\n",
        "print('Specificity = ', specificity)\n",
        "print('Sensitivity = ', sensitivity)\n",
        "print(metrics.classification_report(y_true=test_Y_input,y_pred= predict, digits=4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BqSmGKedXZHF",
        "outputId": "a5044b0e-79a4-4f5c-8a3f-c8e216344898"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForest AUC =  0.8528519449660015\n",
            "FLOPs: 1.0274782405860685e+23\n",
            "MLOPS: 30.23\n",
            "Specificity =  0.7654584221748401\n",
            "Sensitivity =  0.7910447761194029\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8953    0.7655    0.8253       469\n",
            "           1     0.5911    0.7910    0.6766       201\n",
            "\n",
            "    accuracy                         0.7731       670\n",
            "   macro avg     0.7432    0.7783    0.7509       670\n",
            "weighted avg     0.8040    0.7731    0.7807       670\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hj-DMl7gdNX0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}