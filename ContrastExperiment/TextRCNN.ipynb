{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Rz38NZg9eZk",
        "outputId": "ef528632-0f83-4145-b25d-29a99d665888"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def fill_padding(data, max_len, pad_id):\n",
        "    if len(data) < max_len:\n",
        "        pad_len = max_len - len(data)\n",
        "        padding = [pad_id for _ in range(pad_len)]\n",
        "        # try:\n",
        "        # print(\"data: \", data)\n",
        "        # print(\"padding: \", padding)\n",
        "        data = torch.tensor(data + padding)\n",
        "\n",
        "        # except BaseException:\n",
        "        #   print(\"____________________error_________________\")\n",
        "        #   print(data)\n",
        "        #   print(padding)\n",
        "\n",
        "\n",
        "    else:\n",
        "        data = torch.tensor(data[: max_len])\n",
        "    return data\n",
        "\n",
        "\n",
        "class articleDataset(Dataset):\n",
        "    def __init__(self, journal, title, abstruct, label_list, token2id):\n",
        "        self.journal = journal\n",
        "        self.title = title\n",
        "        self.abstruct = abstruct\n",
        "        self.label_list = label_list\n",
        "        self.token2id = token2id\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.journal)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        return {\n",
        "            'journal': self.journal[item],\n",
        "            # 'tokens': fill_padding(self.text_list[item], max_len=self.max_len, pad_id=0),\n",
        "            'title': fill_padding(self.title[item], max_len=32, pad_id=0),\n",
        "            'abstruct': fill_padding(self.abstruct[item], max_len=512, pad_id=0),\n",
        "            'label': torch.tensor(self.label_list[item])\n",
        "        }\n",
        "\n",
        "def shuffle_dataset(journal, title, abstruct, label):\n",
        "    length = len(journal)\n",
        "    rng = np.random.default_rng(1235)\n",
        "    index = np.arange(length)\n",
        "    # print(index)\n",
        "    rng.shuffle(index)\n",
        "    # print(index)\n",
        "    return journal[index], np.array(title)[index], np.array(abstruct)[index], label[index]\n",
        "\n",
        "def preprocess(file_path):\n",
        "    df = pd.read_excel(file_path)\n",
        "    df.replace(np.nan, '[PAD]', inplace=True)\n",
        "    text_list = []\n",
        "    title = df['标题']\n",
        "    abstruct = df['摘要']\n",
        "    # with open(file_path, 'r', encoding='utf-8') as f:\n",
        "    #     f.readline()\n",
        "    for item in title:\n",
        "        text_list.append(item)\n",
        "        # print(item)\n",
        "    for item in abstruct:\n",
        "        text_list.append(item)\n",
        "    return text_list\n",
        "\n",
        "\n",
        "def build_vocab(*text_list):\n",
        "    token_set = set()\n",
        "    for idv_list in text_list:\n",
        "        for tokens in idv_list:\n",
        "            # print(tokens)\n",
        "            for i in tokens.split(' '):\n",
        "                # print(i)\n",
        "                # print(\"\\n\")\n",
        "                token_set.add(i)\n",
        "\n",
        "    token2id, id2token = {}, {}\n",
        "    token2id['[PAD]'] = 0\n",
        "    id2token[0] = '[PAD]'\n",
        "    cnt = 1\n",
        "    for i in token_set:\n",
        "        token2id[i] = cnt\n",
        "        id2token[cnt] = i\n",
        "        cnt += 1\n",
        "\n",
        "    return token2id, id2token"
      ],
      "metadata": {
        "id": "jkN8SodG9jVv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class TextRCNN(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(TextRCNN, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim=128, padding_idx=0)\n",
        "        self.lstm = nn.LSTM(input_size=128,\n",
        "                            hidden_size=256,\n",
        "                            num_layers=2,\n",
        "                            dropout=0.5,\n",
        "                            batch_first=True,\n",
        "                            bidirectional=True)\n",
        "        self.W2 = nn.Linear(640, 256)\n",
        "        self.maxpool = nn.MaxPool1d(512)\n",
        "        self.journal_layer = nn.Sequential(\n",
        "            nn.Linear(16,64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64,16),\n",
        "        )\n",
        "        self.linear = nn.Linear(256 + 16, 2)\n",
        "\n",
        "    def forward(self, journal, title, abstruct):\n",
        "        # x:[batch_size, seq_len, embeding_size]\n",
        "        title = self.embedding(title)\n",
        "        abstruct = self.embedding(abstruct)\n",
        "        embed = torch.cat((title, abstruct), 1)\n",
        "        out, _ = self.lstm(embed)\n",
        "        # print(\"embed: \",embed.shape)\n",
        "        # print(\"out: \", out.shape)\n",
        "        xx = torch.cat((embed, out), 2)\n",
        "        y2 = torch.tanh(self.W2(xx)).permute(0, 2, 1)\n",
        "        y3 = self.maxpool(y2).squeeze(2)\n",
        "        # out = self.fc(y3)\n",
        "        journal_feature = self.journal_layer(journal.float())\n",
        "        out = self.linear(torch.cat((y3, journal_feature.to(torch.float32)), 1))\n",
        "        out = F.softmax(out, dim=1)\n",
        "        return out"
      ],
      "metadata": {
        "id": "wISS80yE9vmk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "def focal_loss(\n",
        "    inputs: torch.Tensor,\n",
        "    targets: torch.Tensor,\n",
        "    alpha: float = 0.7,\n",
        "    gamma: float = 2,\n",
        "    reduction: str = \"mean\",\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        inputs: A float tensor of arbitrary shape.\n",
        "                The predictions which have been sigmod for each example.\n",
        "        targets: A float tensor with the same shape as inputs. Stores the binary\n",
        "                 classification label for each element in inputs\n",
        "                (0 for the negative class and 1 for the positive class).\n",
        "        alpha: (optional) Weighting factor in range (0,1) to balance\n",
        "                positive vs negative examples. Default = -1 (no weighting).\n",
        "        gamma: Exponent of the modulating factor (1 - p_t) to\n",
        "               balance easy vs hard examples.\n",
        "        reduction: 'none' | 'mean' | 'sum'\n",
        "                 'none': No reduction will be applied to the output.\n",
        "                 'mean': The output will be averaged.\n",
        "                 'sum': The output will be summed.\n",
        "    Returns:\n",
        "        Loss tensor with the reduction option applied.\n",
        "    \"\"\"\n",
        "    inputs = inputs.float()\n",
        "    targets = targets.float()\n",
        "    p = inputs\n",
        "    ce_loss = F.binary_cross_entropy(inputs, targets, reduction=\"none\")\n",
        "    p_t = p * targets + (1 - p) * (1 - targets)\n",
        "    loss = ce_loss * ((1 - p_t) ** gamma)\n",
        "\n",
        "    if alpha >= 0:\n",
        "        alpha_t = alpha * targets + (1 - alpha) * (1 - targets)\n",
        "        loss = alpha_t * loss\n",
        "\n",
        "    if reduction == \"mean\":\n",
        "        loss = loss.mean()\n",
        "    elif reduction == \"sum\":\n",
        "        loss = loss.sum()\n",
        "\n",
        "    return loss"
      ],
      "metadata": {
        "id": "IZSmkvM-XLU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install thop"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBx3PglDC1ek",
        "outputId": "55d8429b-99d2-4cf3-874f-37f1b1ebc7a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting thop\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from thop) (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->thop) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->thop) (4.6.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->thop) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->thop) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->thop) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->thop) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->thop) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->thop) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->thop) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->thop) (1.3.0)\n",
            "Installing collected packages: thop\n",
            "Successfully installed thop-0.1.1.post2209072238\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import AdamW\n",
        "# from model import TextRNN\n",
        "# from data_processor import articleDataset, preprocess, build_vocab, shuffle_dataset\n",
        "import torch.nn as nn\n",
        "import os\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, roc_auc_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from thop import profile\n",
        "import time\n",
        "\n",
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
        "os.environ['TORCH_USE_CUDA_DSA'] = '1'\n",
        "\n",
        "batch_size = 64\n",
        "lr = 3e-5\n",
        "EPOCHS = 100\n",
        "\n",
        "\n",
        "def evaluate(model, dataloader):\n",
        "    model.eval()\n",
        "\n",
        "    pred_tags = []\n",
        "    true_tags = []\n",
        "    probs = []\n",
        "    total_loss = 0.\n",
        "    # loss_fn = nn.CrossEntropyLoss()\n",
        "    loss_fn = focal_loss\n",
        "    with torch.no_grad():\n",
        "        # i = 0\n",
        "        for batch in dataloader:\n",
        "            # print(i)\n",
        "            # i += 1\n",
        "            journal = batch['journal'].to(device)\n",
        "            title = batch['title'].to(device)\n",
        "            abstruct = batch['abstruct'].to(device)\n",
        "            label = batch['label'].to(device)\n",
        "\n",
        "            model.zero_grad()\n",
        "            # logits = model(journal, title, abstruct)\n",
        "            # loss = loss_fn(logits, label)\n",
        "            logits = model(journal, title, abstruct)\n",
        "            label = label.to(device=device, dtype=torch.float64)\n",
        "            loss = loss_fn(logits[:, 1].unsqueeze(1), label)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            pred = torch.argmax(logits, dim=1).cpu()\n",
        "            prob = logits[:, 1].unsqueeze(1).cpu()\n",
        "            # print(pred.shape)\n",
        "\n",
        "            pred_tags.extend(pred)\n",
        "            probs.extend(prob)\n",
        "            # label = label.to(device=device, dtype=torch.int64)\n",
        "            # print(label.squeeze(1).shape)\n",
        "            true_tags.extend(label.squeeze(1).cpu())\n",
        "            # print(classification_report(true_tags, pred_tags))\n",
        "\n",
        "    # 计算specificity、sensitivity\n",
        "    tn, fp, fn, tp = confusion_matrix(true_tags, pred_tags).ravel()\n",
        "    specificity = tn / (tn + fp)\n",
        "    sensitivity = tp / (tp + fn)\n",
        "\n",
        "\n",
        "\n",
        "    assert len(pred_tags) == len(true_tags)\n",
        "\n",
        "    return {\n",
        "        'loss': total_loss / len(dataloader),\n",
        "        'precision': precision_score(true_tags, pred_tags),\n",
        "        'recall': recall_score(true_tags, pred_tags),\n",
        "        'f1': f1_score(true_tags, pred_tags),\n",
        "        'accuracy': accuracy_score(true_tags, pred_tags),\n",
        "        'classification_report': classification_report(true_tags, pred_tags, digits=4),\n",
        "        'auc': roc_auc_score(true_tags, probs),\n",
        "        'specificity': specificity,\n",
        "        'sensitivity': sensitivity\n",
        "    }\n",
        "\n",
        "\n",
        "def main():\n",
        "    # 建立词汇表\n",
        "    text_list = preprocess('/content/drive/MyDrive/neckpain_data/新样本.xlsx')\n",
        "    token2id, id2token = build_vocab(text_list)\n",
        "\n",
        "    # 建立训练集、测试集\n",
        "    df = pd.read_excel('/content/drive/MyDrive/neckpain_data/新样本.xlsx')\n",
        "    # df.replace(np.nan, '[PAD]', inplace=True)\n",
        "    df_0 = df.loc[df['正样本'] == 0]\n",
        "    df_1 = df.loc[df['正样本'] == 1]\n",
        "    title_0 = df_0['标题'].values\n",
        "    title_1 = df_1['标题'].values\n",
        "    abstruct_0 = df_0['摘要']\n",
        "    abstruct_1 = df_1['摘要']\n",
        "    abstruct_0.replace(np.nan, '[PAD]', inplace=True)\n",
        "    abstruct_1.replace(np.nan, '[PAD]', inplace=True)\n",
        "    abstruct_0 = abstruct_0.values\n",
        "    abstruct_1 = abstruct_1.values\n",
        "    df_0.replace(np.nan, 0, inplace=True)\n",
        "    df_1.replace(np.nan, 0, inplace=True)\n",
        "\n",
        "    X_0 = df_0.drop(columns=['标题', '摘要', '正样本', '关键词', '期刊', '期刊简称', 'ID', 'academy_sciences']).values\n",
        "    X_1 = df_1.drop(columns=['标题', '摘要', '正样本', '关键词', '期刊', '期刊简称', 'ID', 'academy_sciences']).values\n",
        "    Y_0 = df_0['正样本'].values\n",
        "    Y_1 = df_1['正样本'].values\n",
        "\n",
        "    rs = np.random.RandomState(42)\n",
        "    L = list(rs.randint(0, len(X_0), int(7 / 3 * len(X_1))))\n",
        "    X_0 = X_0[L]\n",
        "    Y_0 = Y_0[L]\n",
        "    title_0 = title_0[L]\n",
        "    abstruct_0 = abstruct_0[L]\n",
        "\n",
        "    journal_train_X_0, journal_test_X_0, train_Y_0, test_Y_0 = train_test_split(X_0, Y_0, train_size=0.80, random_state=42)\n",
        "    journal_train_X_1, journal_test_X_1, train_Y_1, test_Y_1 = train_test_split(X_1, Y_1, train_size=0.80, random_state=42)\n",
        "    title_train_X_0, title_test_X_0, _, _ = train_test_split(title_0, Y_0, train_size=0.80, random_state=42)\n",
        "    title_train_X_1, title_test_X_1, _, _ = train_test_split(title_1, Y_1, train_size=0.80, random_state=42)\n",
        "    abstruct_train_X_0, abstruct_test_X_0, _, _ = train_test_split(abstruct_0, Y_0, train_size=0.80, random_state=42)\n",
        "    abstruct_train_X_1, abstruct_test_X_1, _, _ = train_test_split(abstruct_1, Y_1, train_size=0.80, random_state=42)\n",
        "\n",
        "    # print(title_train_X_1)\n",
        "\n",
        "    title_train_X_1 = [[token2id[i] for i in text.split(' ')] for text in title_train_X_1]\n",
        "    title_train_X_0 = [[token2id[i] for i in text.split(' ')] for text in title_train_X_0]\n",
        "    abstruct_train_X_1 = [[token2id[i] for i in text.split(' ')] for text in abstruct_train_X_1]\n",
        "    abstruct_train_X_0 = [[token2id[i] for i in text.split(' ')] for text in abstruct_train_X_0]\n",
        "\n",
        "    title_test_X_1 = [[token2id[i] for i in text.split(' ')] for text in title_test_X_1]\n",
        "    title_test_X_0 = [[token2id[i] for i in text.split(' ')] for text in title_test_X_0]\n",
        "    abstruct_test_X_1 = [[token2id[i] for i in text.split(' ')] for text in abstruct_test_X_1]\n",
        "    abstruct_test_X_0 = [[token2id[i] for i in text.split(' ')] for text in abstruct_test_X_0]\n",
        "\n",
        "    train_journal = torch.from_numpy(np.vstack((journal_train_X_1.astype(float), journal_train_X_0.astype(float)))).to(device)\n",
        "    # train_journal = np.vstack((journal_train_X_1, journal_train_X_0))\n",
        "    train_title = title_train_X_1 + title_train_X_0\n",
        "    train_abstruct = abstruct_train_X_1 + abstruct_train_X_0\n",
        "    train_Y = torch.from_numpy(np.vstack((train_Y_1.reshape(len(train_Y_1), 1), train_Y_0.reshape(len(train_Y_0), 1)))).to(device)\n",
        "    # train_Y = np.vstack((train_Y_1.reshape(len(train_Y_1), 1), train_Y_0.reshape(len(train_Y_0), 1)))\n",
        "    train_journal, train_title, train_abstruct, train_Y = shuffle_dataset(train_journal, train_title, train_abstruct, train_Y)\n",
        "\n",
        "    test_journal = torch.from_numpy(np.vstack((journal_test_X_1.astype(float), journal_test_X_0.astype(float)))).to(device)\n",
        "    # test_journal = np.vstack((journal_test_X_1, journal_test_X_0))\n",
        "    test_title = title_test_X_1 + title_test_X_0\n",
        "    test_abstruct = abstruct_test_X_1 + abstruct_test_X_0\n",
        "    test_Y = torch.from_numpy(np.vstack((test_Y_1.reshape(len(test_Y_1), 1), test_Y_0.reshape(len(test_Y_0), 1)))).to(device)\n",
        "    # test_Y = np.vstack((test_Y_1.reshape(len(test_Y_1), 1), test_Y_0.reshape(len(test_Y_0), 1)))\n",
        "    test_journal, test_title, test_abstruct, test_Y = shuffle_dataset(test_journal, test_title, test_abstruct, test_Y)\n",
        "\n",
        "\n",
        "\n",
        "    train_dataset = articleDataset(train_journal, train_title, train_abstruct, train_Y, token2id)\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_dataset = articleDataset(test_journal, test_title, test_abstruct, test_Y, token2id)\n",
        "    val_dataloader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "\n",
        "    model = TextRCNN(vocab_size=len(token2id)).to(device)\n",
        "    # for param in model.parameters():\n",
        "    #   param = 0\n",
        "\n",
        "    optimizer = AdamW(model.parameters(), lr=lr)\n",
        "    # loss_fn = nn.CrossEntropyLoss()\n",
        "    loss_fn = focal_loss\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        model.train()\n",
        "        start_time = time.time()\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "            journal = batch['journal'].to(device)\n",
        "            title = batch['title'].to(device)\n",
        "            abstruct = batch['abstruct'].to(device)\n",
        "            label = batch['label'].to(device)\n",
        "\n",
        "            model.zero_grad()\n",
        "\n",
        "            logits = model(journal, title, abstruct)\n",
        "            # print(logits[:, 1].unsqueeze(1))\n",
        "            # print(label)\n",
        "            label = label.to(device=device, dtype=torch.float64)\n",
        "            loss = loss_fn(logits[:, 1].unsqueeze(1), label)/batch_size\n",
        "            # print(loss.item())\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if step % (len(train_dataloader) // 9) == 0:\n",
        "                print(\"epoch: {} step: {}/{}\".format(epoch, step, len(train_dataloader)))\n",
        "\n",
        "        end_time = time.time()\n",
        "\n",
        "        # 计算每秒钟的训练样本数（即MLOPS）\n",
        "        num_samples = len(train_dataset)\n",
        "        training_time = end_time - start_time\n",
        "        samples_per_second = num_samples / training_time\n",
        "\n",
        "        torch.save(model.state_dict(), '/content/drive/MyDrive/neckpain_model/model_last.pt')\n",
        "\n",
        "        train_metrics = evaluate(model, train_dataloader)\n",
        "        print(\"test\")\n",
        "        print(\"epoch: {} train_loss: {} train_acc: {:.2f}% train_f1: {:.2f}%\".format(epoch,\n",
        "                                                                                     train_metrics['loss'],\n",
        "                                                                                     train_metrics['accuracy'] * 100,\n",
        "                                                                                     train_metrics['f1'] * 100))\n",
        "        # print(train_metrics['classification_report'])\n",
        "        val_metrics = evaluate(model, val_dataloader)\n",
        "        print(\"          val_loss: {} val_acc {:.2f}% val_f1: {:.2f}%\".format(val_metrics['loss'],\n",
        "                                                                               val_metrics['accuracy'] * 100,\n",
        "                                                                               val_metrics['f1'] * 100))\n",
        "        print('TextRCNN AUC = ', val_metrics['auc'])\n",
        "        print('Specificity = ', val_metrics['specificity'])\n",
        "        print('Sensitivity = ', val_metrics['sensitivity'])\n",
        "        print(val_metrics['classification_report'])\n",
        "        # 输出模型信息\n",
        "        flops, params = profile(model, inputs=(journal, title, abstruct))\n",
        "        print(\"Flops: {:.2f}\".format(flops))\n",
        "        print(\"MLOPS: {:.2f}\".format(samples_per_second))\n",
        "        # eval(model, test_journal, test_title, test_abstruct, test_Y, token2id)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    if not os.path.exists('/content/drive/MyDrive/neckpain_model'):\n",
        "        os.mkdir('/content/drive/MyDrive/neckpain_model')\n",
        "\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "LhQbgSZJ9ye7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "34fc5cf1-1479-485b-e201-095d5694d578"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-d361f939f5d0>:98: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  abstruct_0.replace(np.nan, '[PAD]', inplace=True)\n",
            "<ipython-input-7-d361f939f5d0>:99: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  abstruct_1.replace(np.nan, '[PAD]', inplace=True)\n",
            "<ipython-input-7-d361f939f5d0>:102: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_0.replace(np.nan, 0, inplace=True)\n",
            "<ipython-input-7-d361f939f5d0>:103: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_1.replace(np.nan, 0, inplace=True)\n",
            "<ipython-input-1-f0d979b1a134>:54: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  return journal[index], np.array(title)[index], np.array(abstruct)[index], label[index]\n",
            "<ipython-input-1-f0d979b1a134>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  'label': torch.tensor(self.label_list[item])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0 step: 0/42\n",
            "epoch: 0 step: 4/42\n",
            "epoch: 0 step: 8/42\n",
            "epoch: 0 step: 12/42\n",
            "epoch: 0 step: 16/42\n",
            "epoch: 0 step: 20/42\n",
            "epoch: 0 step: 24/42\n",
            "epoch: 0 step: 28/42\n",
            "epoch: 0 step: 32/42\n",
            "epoch: 0 step: 36/42\n",
            "epoch: 0 step: 40/42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "<ipython-input-1-f0d979b1a134>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  'label': torch.tensor(self.label_list[item])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test\n",
            "epoch: 0 train_loss: 0.07183581315690563 train_acc: 61.16% train_f1: 48.69%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          val_loss: 0.07055515795946121 val_acc 62.09% val_f1: 49.80%\n",
            "TextRCNN AUC =  0.6531203258759507\n",
            "Specificity =  0.6183368869936035\n",
            "Sensitivity =  0.6268656716417911\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.7945    0.6183    0.6954       469\n",
            "         1.0     0.4131    0.6269    0.4980       201\n",
            "\n",
            "    accuracy                         0.6209       670\n",
            "   macro avg     0.6038    0.6226    0.5967       670\n",
            "weighted avg     0.6801    0.6209    0.6362       670\n",
            "\n",
            "[INFO] Register count_lstm() for <class 'torch.nn.modules.rnn.LSTM'>.\n",
            "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool1d'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
            "Flops: 77364082432.00\n",
            "MLOPS: 135.74\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-f0d979b1a134>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  'label': torch.tensor(self.label_list[item])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1 step: 0/42\n",
            "epoch: 1 step: 4/42\n",
            "epoch: 1 step: 8/42\n",
            "epoch: 1 step: 12/42\n",
            "epoch: 1 step: 16/42\n",
            "epoch: 1 step: 20/42\n",
            "epoch: 1 step: 24/42\n",
            "epoch: 1 step: 28/42\n",
            "epoch: 1 step: 32/42\n",
            "epoch: 1 step: 36/42\n",
            "epoch: 1 step: 40/42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "<ipython-input-1-f0d979b1a134>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  'label': torch.tensor(self.label_list[item])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test\n",
            "epoch: 1 train_loss: 0.06961633123102642 train_acc: 65.71% train_f1: 48.80%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "<ipython-input-1-f0d979b1a134>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  'label': torch.tensor(self.label_list[item])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          val_loss: 0.06864303214983507 val_acc 67.01% val_f1: 50.11%\n",
            "TextRCNN AUC =  0.670252150760059\n",
            "Specificity =  0.720682302771855\n",
            "Sensitivity =  0.5522388059701493\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.7897    0.7207    0.7536       469\n",
            "         1.0     0.4587    0.5522    0.5011       201\n",
            "\n",
            "    accuracy                         0.6701       670\n",
            "   macro avg     0.6242    0.6365    0.6274       670\n",
            "weighted avg     0.6904    0.6701    0.6779       670\n",
            "\n",
            "[INFO] Register count_lstm() for <class 'torch.nn.modules.rnn.LSTM'>.\n",
            "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool1d'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
            "Flops: 77364082432.00\n",
            "MLOPS: 179.76\n",
            "epoch: 2 step: 0/42\n",
            "epoch: 2 step: 4/42\n",
            "epoch: 2 step: 8/42\n",
            "epoch: 2 step: 12/42\n",
            "epoch: 2 step: 16/42\n",
            "epoch: 2 step: 20/42\n",
            "epoch: 2 step: 24/42\n",
            "epoch: 2 step: 28/42\n",
            "epoch: 2 step: 32/42\n",
            "epoch: 2 step: 36/42\n",
            "epoch: 2 step: 40/42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "<ipython-input-1-f0d979b1a134>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  'label': torch.tensor(self.label_list[item])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test\n",
            "epoch: 2 train_loss: 0.06787389357175146 train_acc: 67.61% train_f1: 50.90%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "<ipython-input-1-f0d979b1a134>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  'label': torch.tensor(self.label_list[item])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          val_loss: 0.06725160574371164 val_acc 68.81% val_f1: 52.17%\n",
            "TextRCNN AUC =  0.6923166682578578\n",
            "Specificity =  0.7398720682302772\n",
            "Sensitivity =  0.5671641791044776\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.7995    0.7399    0.7685       469\n",
            "         1.0     0.4831    0.5672    0.5217       201\n",
            "\n",
            "    accuracy                         0.6881       670\n",
            "   macro avg     0.6413    0.6535    0.6451       670\n",
            "weighted avg     0.7046    0.6881    0.6945       670\n",
            "\n",
            "[INFO] Register count_lstm() for <class 'torch.nn.modules.rnn.LSTM'>.\n",
            "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool1d'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
            "Flops: 77364082432.00\n",
            "MLOPS: 189.41\n",
            "epoch: 3 step: 0/42\n",
            "epoch: 3 step: 4/42\n",
            "epoch: 3 step: 8/42\n",
            "epoch: 3 step: 12/42\n",
            "epoch: 3 step: 16/42\n",
            "epoch: 3 step: 20/42\n",
            "epoch: 3 step: 24/42\n",
            "epoch: 3 step: 28/42\n",
            "epoch: 3 step: 32/42\n",
            "epoch: 3 step: 36/42\n",
            "epoch: 3 step: 40/42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test\n",
            "epoch: 3 train_loss: 0.06638838137899127 train_acc: 68.32% train_f1: 53.38%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-f0d979b1a134>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  'label': torch.tensor(self.label_list[item])\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "<ipython-input-1-f0d979b1a134>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  'label': torch.tensor(self.label_list[item])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          val_loss: 0.06610843471505425 val_acc 69.10% val_f1: 53.69%\n",
            "TextRCNN AUC =  0.716131496037934\n",
            "Specificity =  0.7313432835820896\n",
            "Sensitivity =  0.5970149253731343\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.8090    0.7313    0.7682       469\n",
            "         1.0     0.4878    0.5970    0.5369       201\n",
            "\n",
            "    accuracy                         0.6910       670\n",
            "   macro avg     0.6484    0.6642    0.6526       670\n",
            "weighted avg     0.7126    0.6910    0.6988       670\n",
            "\n",
            "[INFO] Register count_lstm() for <class 'torch.nn.modules.rnn.LSTM'>.\n",
            "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool1d'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
            "Flops: 77364082432.00\n",
            "MLOPS: 188.16\n",
            "epoch: 4 step: 0/42\n",
            "epoch: 4 step: 4/42\n",
            "epoch: 4 step: 8/42\n",
            "epoch: 4 step: 12/42\n",
            "epoch: 4 step: 16/42\n",
            "epoch: 4 step: 20/42\n",
            "epoch: 4 step: 24/42\n",
            "epoch: 4 step: 28/42\n",
            "epoch: 4 step: 32/42\n",
            "epoch: 4 step: 36/42\n",
            "epoch: 4 step: 40/42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "<ipython-input-1-f0d979b1a134>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  'label': torch.tensor(self.label_list[item])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test\n",
            "epoch: 4 train_loss: 0.06500779908327829 train_acc: 70.71% train_f1: 55.52%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          val_loss: 0.06502059643918817 val_acc 70.90% val_f1: 55.58%\n",
            "TextRCNN AUC =  0.7375595370694501\n",
            "Specificity =  0.7526652452025586\n",
            "Sensitivity =  0.6069651741293532\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.8171    0.7527    0.7836       469\n",
            "         1.0     0.5126    0.6070    0.5558       201\n",
            "\n",
            "    accuracy                         0.7090       670\n",
            "   macro avg     0.6649    0.6798    0.6697       670\n",
            "weighted avg     0.7258    0.7090    0.7152       670\n",
            "\n",
            "[INFO] Register count_lstm() for <class 'torch.nn.modules.rnn.LSTM'>.\n",
            "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool1d'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
            "Flops: 77364082432.00\n",
            "MLOPS: 181.80\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-f0d979b1a134>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  'label': torch.tensor(self.label_list[item])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 5 step: 0/42\n",
            "epoch: 5 step: 4/42\n",
            "epoch: 5 step: 8/42\n",
            "epoch: 5 step: 12/42\n",
            "epoch: 5 step: 16/42\n",
            "epoch: 5 step: 20/42\n",
            "epoch: 5 step: 24/42\n",
            "epoch: 5 step: 28/42\n",
            "epoch: 5 step: 32/42\n",
            "epoch: 5 step: 36/42\n",
            "epoch: 5 step: 40/42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "<ipython-input-1-f0d979b1a134>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  'label': torch.tensor(self.label_list[item])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test\n",
            "epoch: 5 train_loss: 0.06378516049257346 train_acc: 71.27% train_f1: 57.69%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "<ipython-input-1-f0d979b1a134>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  'label': torch.tensor(self.label_list[item])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          val_loss: 0.06407058780843561 val_acc 71.34% val_f1: 56.95%\n",
            "TextRCNN AUC =  0.7513074287411556\n",
            "Specificity =  0.7484008528784648\n",
            "Sensitivity =  0.6318407960199005\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.8259    0.7484    0.7852       469\n",
            "         1.0     0.5184    0.6318    0.5695       201\n",
            "\n",
            "    accuracy                         0.7134       670\n",
            "   macro avg     0.6721    0.6901    0.6774       670\n",
            "weighted avg     0.7336    0.7134    0.7205       670\n",
            "\n",
            "[INFO] Register count_lstm() for <class 'torch.nn.modules.rnn.LSTM'>.\n",
            "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool1d'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
            "Flops: 77364082432.00\n",
            "MLOPS: 181.30\n",
            "epoch: 6 step: 0/42\n",
            "epoch: 6 step: 4/42\n",
            "epoch: 6 step: 8/42\n",
            "epoch: 6 step: 12/42\n",
            "epoch: 6 step: 16/42\n",
            "epoch: 6 step: 20/42\n",
            "epoch: 6 step: 24/42\n",
            "epoch: 6 step: 28/42\n",
            "epoch: 6 step: 32/42\n",
            "epoch: 6 step: 36/42\n",
            "epoch: 6 step: 40/42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "<ipython-input-1-f0d979b1a134>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  'label': torch.tensor(self.label_list[item])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test\n",
            "epoch: 6 train_loss: 0.06265163483719031 train_acc: 73.02% train_f1: 60.08%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "<ipython-input-1-f0d979b1a134>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  'label': torch.tensor(self.label_list[item])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          val_loss: 0.06322634592652321 val_acc 72.24% val_f1: 58.48%\n",
            "TextRCNN AUC =  0.7677391295123529\n",
            "Specificity =  0.7526652452025586\n",
            "Sensitivity =  0.6517412935323383\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.8345    0.7527    0.7915       469\n",
            "         1.0     0.5304    0.6517    0.5848       201\n",
            "\n",
            "    accuracy                         0.7224       670\n",
            "   macro avg     0.6824    0.7022    0.6882       670\n",
            "weighted avg     0.7433    0.7224    0.7295       670\n",
            "\n",
            "[INFO] Register count_lstm() for <class 'torch.nn.modules.rnn.LSTM'>.\n",
            "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool1d'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
            "Flops: 77364082432.00\n",
            "MLOPS: 189.27\n",
            "epoch: 7 step: 0/42\n",
            "epoch: 7 step: 4/42\n",
            "epoch: 7 step: 8/42\n",
            "epoch: 7 step: 12/42\n",
            "epoch: 7 step: 16/42\n",
            "epoch: 7 step: 20/42\n",
            "epoch: 7 step: 24/42\n",
            "epoch: 7 step: 28/42\n",
            "epoch: 7 step: 32/42\n",
            "epoch: 7 step: 36/42\n",
            "epoch: 7 step: 40/42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "<ipython-input-1-f0d979b1a134>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  'label': torch.tensor(self.label_list[item])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test\n",
            "epoch: 7 train_loss: 0.0619443722424053 train_acc: 75.15% train_f1: 58.79%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "<ipython-input-1-f0d979b1a134>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  'label': torch.tensor(self.label_list[item])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          val_loss: 0.06275616823272272 val_acc 75.22% val_f1: 57.65%\n",
            "TextRCNN AUC =  0.7853377038050686\n",
            "Specificity =  0.8336886993603412\n",
            "Sensitivity =  0.5621890547263682\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.8163    0.8337    0.8249       469\n",
            "         1.0     0.5916    0.5622    0.5765       201\n",
            "\n",
            "    accuracy                         0.7522       670\n",
            "   macro avg     0.7040    0.6979    0.7007       670\n",
            "weighted avg     0.7489    0.7522    0.7504       670\n",
            "\n",
            "[INFO] Register count_lstm() for <class 'torch.nn.modules.rnn.LSTM'>.\n",
            "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool1d'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
            "Flops: 77364082432.00\n",
            "MLOPS: 186.96\n",
            "epoch: 8 step: 0/42\n",
            "epoch: 8 step: 4/42\n",
            "epoch: 8 step: 8/42\n",
            "epoch: 8 step: 12/42\n",
            "epoch: 8 step: 16/42\n",
            "epoch: 8 step: 20/42\n",
            "epoch: 8 step: 24/42\n",
            "epoch: 8 step: 28/42\n",
            "epoch: 8 step: 32/42\n",
            "epoch: 8 step: 36/42\n",
            "epoch: 8 step: 40/42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test\n",
            "epoch: 8 train_loss: 0.06072980529140858 train_acc: 75.82% train_f1: 61.70%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-f0d979b1a134>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  'label': torch.tensor(self.label_list[item])\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "<ipython-input-1-f0d979b1a134>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  'label': torch.tensor(self.label_list[item])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          val_loss: 0.061838849701664665 val_acc 75.82% val_f1: 60.29%\n",
            "TextRCNN AUC =  0.7951394413858215\n",
            "Specificity =  0.8208955223880597\n",
            "Sensitivity =  0.6119402985074627\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.8315    0.8209    0.8262       469\n",
            "         1.0     0.5942    0.6119    0.6029       201\n",
            "\n",
            "    accuracy                         0.7582       670\n",
            "   macro avg     0.7129    0.7164    0.7146       670\n",
            "weighted avg     0.7603    0.7582    0.7592       670\n",
            "\n",
            "[INFO] Register count_lstm() for <class 'torch.nn.modules.rnn.LSTM'>.\n",
            "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool1d'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
            "Flops: 77364082432.00\n",
            "MLOPS: 186.65\n",
            "epoch: 9 step: 0/42\n",
            "epoch: 9 step: 4/42\n",
            "epoch: 9 step: 8/42\n",
            "epoch: 9 step: 12/42\n",
            "epoch: 9 step: 16/42\n",
            "epoch: 9 step: 20/42\n",
            "epoch: 9 step: 24/42\n",
            "epoch: 9 step: 28/42\n",
            "epoch: 9 step: 32/42\n",
            "epoch: 9 step: 36/42\n",
            "epoch: 9 step: 40/42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "<ipython-input-1-f0d979b1a134>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  'label': torch.tensor(self.label_list[item])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test\n",
            "epoch: 9 train_loss: 0.05963966685036818 train_acc: 76.12% train_f1: 64.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "<ipython-input-1-f0d979b1a134>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  'label': torch.tensor(self.label_list[item])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          val_loss: 0.06099905920299617 val_acc 74.63% val_f1: 60.83%\n",
            "TextRCNN AUC =  0.8015254219308575\n",
            "Specificity =  0.7846481876332623\n",
            "Sensitivity =  0.6567164179104478\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.8421    0.7846    0.8124       469\n",
            "         1.0     0.5665    0.6567    0.6083       201\n",
            "\n",
            "    accuracy                         0.7463       670\n",
            "   macro avg     0.7043    0.7207    0.7103       670\n",
            "weighted avg     0.7594    0.7463    0.7511       670\n",
            "\n",
            "[INFO] Register count_lstm() for <class 'torch.nn.modules.rnn.LSTM'>.\n",
            "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool1d'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
            "Flops: 77364082432.00\n",
            "MLOPS: 185.07\n",
            "epoch: 10 step: 0/42\n",
            "epoch: 10 step: 4/42\n",
            "epoch: 10 step: 8/42\n",
            "epoch: 10 step: 12/42\n",
            "epoch: 10 step: 16/42\n",
            "epoch: 10 step: 20/42\n",
            "epoch: 10 step: 24/42\n",
            "epoch: 10 step: 28/42\n",
            "epoch: 10 step: 32/42\n",
            "epoch: 10 step: 36/42\n",
            "epoch: 10 step: 40/42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "<ipython-input-1-f0d979b1a134>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  'label': torch.tensor(self.label_list[item])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test\n",
            "epoch: 10 train_loss: 0.058744278514669054 train_acc: 76.31% train_f1: 64.54%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "<ipython-input-1-f0d979b1a134>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  'label': torch.tensor(self.label_list[item])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          val_loss: 0.06033283607526259 val_acc 75.07% val_f1: 61.96%\n",
            "TextRCNN AUC =  0.8083781518845008\n",
            "Specificity =  0.7825159914712153\n",
            "Sensitivity =  0.6766169154228856\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.8495    0.7825    0.8147       469\n",
            "         1.0     0.5714    0.6766    0.6196       201\n",
            "\n",
            "    accuracy                         0.7507       670\n",
            "   macro avg     0.7105    0.7296    0.7171       670\n",
            "weighted avg     0.7661    0.7507    0.7561       670\n",
            "\n",
            "[INFO] Register count_lstm() for <class 'torch.nn.modules.rnn.LSTM'>.\n",
            "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool1d'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
            "Flops: 77364082432.00\n",
            "MLOPS: 185.27\n",
            "epoch: 11 step: 0/42\n",
            "epoch: 11 step: 4/42\n",
            "epoch: 11 step: 8/42\n",
            "epoch: 11 step: 12/42\n",
            "epoch: 11 step: 16/42\n",
            "epoch: 11 step: 20/42\n",
            "epoch: 11 step: 24/42\n",
            "epoch: 11 step: 28/42\n",
            "epoch: 11 step: 32/42\n",
            "epoch: 11 step: 36/42\n",
            "epoch: 11 step: 40/42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "<ipython-input-1-f0d979b1a134>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  'label': torch.tensor(self.label_list[item])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test\n",
            "epoch: 11 train_loss: 0.057896554558759646 train_acc: 78.69% train_f1: 66.31%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "<ipython-input-1-f0d979b1a134>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  'label': torch.tensor(self.label_list[item])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          val_loss: 0.05983347784389149 val_acc 76.27% val_f1: 61.87%\n",
            "TextRCNN AUC =  0.8196756091610179\n",
            "Specificity =  0.814498933901919\n",
            "Sensitivity =  0.6417910447761194\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.8414    0.8145    0.8277       469\n",
            "         1.0     0.5972    0.6418    0.6187       201\n",
            "\n",
            "    accuracy                         0.7627       670\n",
            "   macro avg     0.7193    0.7281    0.7232       670\n",
            "weighted avg     0.7682    0.7627    0.7650       670\n",
            "\n",
            "[INFO] Register count_lstm() for <class 'torch.nn.modules.rnn.LSTM'>.\n",
            "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool1d'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
            "Flops: 77364082432.00\n",
            "MLOPS: 188.33\n",
            "epoch: 12 step: 0/42\n",
            "epoch: 12 step: 4/42\n",
            "epoch: 12 step: 8/42\n",
            "epoch: 12 step: 12/42\n",
            "epoch: 12 step: 16/42\n",
            "epoch: 12 step: 20/42\n",
            "epoch: 12 step: 24/42\n",
            "epoch: 12 step: 28/42\n",
            "epoch: 12 step: 32/42\n",
            "epoch: 12 step: 36/42\n",
            "epoch: 12 step: 40/42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test\n",
            "epoch: 12 train_loss: 0.057033603301360494 train_acc: 76.34% train_f1: 66.56%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-f0d979b1a134>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  'label': torch.tensor(self.label_list[item])\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          val_loss: 0.059149631383744156 val_acc 74.03% val_f1: 62.50%\n",
            "TextRCNN AUC =  0.8200468870996828\n",
            "Specificity =  0.7484008528784648\n",
            "Sensitivity =  0.7213930348258707\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.8624    0.7484    0.8014       469\n",
            "         1.0     0.5513    0.7214    0.6250       201\n",
            "\n",
            "    accuracy                         0.7403       670\n",
            "   macro avg     0.7069    0.7349    0.7132       670\n",
            "weighted avg     0.7691    0.7403    0.7485       670\n",
            "\n",
            "[INFO] Register count_lstm() for <class 'torch.nn.modules.rnn.LSTM'>.\n",
            "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool1d'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
            "Flops: 77364082432.00\n",
            "MLOPS: 186.70\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-f0d979b1a134>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  'label': torch.tensor(self.label_list[item])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 13 step: 0/42\n",
            "epoch: 13 step: 4/42\n",
            "epoch: 13 step: 8/42\n",
            "epoch: 13 step: 12/42\n",
            "epoch: 13 step: 16/42\n",
            "epoch: 13 step: 20/42\n",
            "epoch: 13 step: 24/42\n",
            "epoch: 13 step: 28/42\n",
            "epoch: 13 step: 32/42\n",
            "epoch: 13 step: 36/42\n",
            "epoch: 13 step: 40/42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "<ipython-input-1-f0d979b1a134>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  'label': torch.tensor(self.label_list[item])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test\n",
            "epoch: 13 train_loss: 0.056142122706487066 train_acc: 76.90% train_f1: 67.44%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "<ipython-input-1-f0d979b1a134>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  'label': torch.tensor(self.label_list[item])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          val_loss: 0.05855407972227444 val_acc 74.78% val_f1: 63.66%\n",
            "TextRCNN AUC =  0.8257645673551222\n",
            "Specificity =  0.7526652452025586\n",
            "Sensitivity =  0.736318407960199\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.8695    0.7527    0.8069       469\n",
            "         1.0     0.5606    0.7363    0.6366       201\n",
            "\n",
            "    accuracy                         0.7478       670\n",
            "   macro avg     0.7150    0.7445    0.7217       670\n",
            "weighted avg     0.7768    0.7478    0.7558       670\n",
            "\n",
            "[INFO] Register count_lstm() for <class 'torch.nn.modules.rnn.LSTM'>.\n",
            "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool1d'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
            "Flops: 77364082432.00\n",
            "MLOPS: 185.66\n",
            "epoch: 14 step: 0/42\n",
            "epoch: 14 step: 4/42\n",
            "epoch: 14 step: 8/42\n",
            "epoch: 14 step: 12/42\n",
            "epoch: 14 step: 16/42\n",
            "epoch: 14 step: 20/42\n",
            "epoch: 14 step: 24/42\n",
            "epoch: 14 step: 28/42\n",
            "epoch: 14 step: 32/42\n",
            "epoch: 14 step: 36/42\n",
            "epoch: 14 step: 40/42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "<ipython-input-1-f0d979b1a134>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  'label': torch.tensor(self.label_list[item])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test\n",
            "epoch: 14 train_loss: 0.055162779188581874 train_acc: 78.47% train_f1: 69.03%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "<ipython-input-1-f0d979b1a134>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  'label': torch.tensor(self.label_list[item])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          val_loss: 0.05790964649482207 val_acc 76.12% val_f1: 64.76%\n",
            "TextRCNN AUC =  0.8330522228940584\n",
            "Specificity =  0.7739872068230277\n",
            "Sensitivity =  0.7313432835820896\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.8705    0.7740    0.8194       469\n",
            "         1.0     0.5810    0.7313    0.6476       201\n",
            "\n",
            "    accuracy                         0.7612       670\n",
            "   macro avg     0.7258    0.7527    0.7335       670\n",
            "weighted avg     0.7837    0.7612    0.7679       670\n",
            "\n",
            "[INFO] Register count_lstm() for <class 'torch.nn.modules.rnn.LSTM'>.\n",
            "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool1d'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
            "Flops: 77364082432.00\n",
            "MLOPS: 184.97\n",
            "epoch: 15 step: 0/42\n",
            "epoch: 15 step: 4/42\n",
            "epoch: 15 step: 8/42\n",
            "epoch: 15 step: 12/42\n",
            "epoch: 15 step: 16/42\n",
            "epoch: 15 step: 20/42\n",
            "epoch: 15 step: 24/42\n",
            "epoch: 15 step: 28/42\n",
            "epoch: 15 step: 32/42\n",
            "epoch: 15 step: 36/42\n",
            "epoch: 15 step: 40/42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "<ipython-input-1-f0d979b1a134>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  'label': torch.tensor(self.label_list[item])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test\n",
            "epoch: 15 train_loss: 0.05417122922482945 train_acc: 80.22% train_f1: 70.78%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "<ipython-input-1-f0d979b1a134>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  'label': torch.tensor(self.label_list[item])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          val_loss: 0.05729347298091108 val_acc 76.72% val_f1: 65.18%\n",
            "TextRCNN AUC =  0.8392896922636286\n",
            "Specificity =  0.7846481876332623\n",
            "Sensitivity =  0.7263681592039801\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.8700    0.7846    0.8251       469\n",
            "         1.0     0.5911    0.7264    0.6518       201\n",
            "\n",
            "    accuracy                         0.7672       670\n",
            "   macro avg     0.7305    0.7555    0.7384       670\n",
            "weighted avg     0.7863    0.7672    0.7731       670\n",
            "\n",
            "[INFO] Register count_lstm() for <class 'torch.nn.modules.rnn.LSTM'>.\n",
            "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool1d'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
            "Flops: 77364082432.00\n",
            "MLOPS: 186.59\n",
            "epoch: 16 step: 0/42\n",
            "epoch: 16 step: 4/42\n",
            "epoch: 16 step: 8/42\n",
            "epoch: 16 step: 12/42\n",
            "epoch: 16 step: 16/42\n",
            "epoch: 16 step: 20/42\n",
            "epoch: 16 step: 24/42\n",
            "epoch: 16 step: 28/42\n",
            "epoch: 16 step: 32/42\n",
            "epoch: 16 step: 36/42\n",
            "epoch: 16 step: 40/42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test\n",
            "epoch: 16 train_loss: 0.053119992482520285 train_acc: 81.60% train_f1: 72.41%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-f0d979b1a134>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  'label': torch.tensor(self.label_list[item])\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          val_loss: 0.05662190169095993 val_acc 77.31% val_f1: 65.77%\n",
            "TextRCNN AUC =  0.845951479277387\n",
            "Specificity =  0.7931769722814499\n",
            "Sensitivity =  0.7263681592039801\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.8712    0.7932    0.8304       469\n",
            "         1.0     0.6008    0.7264    0.6577       201\n",
            "\n",
            "    accuracy                         0.7731       670\n",
            "   macro avg     0.7360    0.7598    0.7440       670\n",
            "weighted avg     0.7901    0.7731    0.7785       670\n",
            "\n",
            "[INFO] Register count_lstm() for <class 'torch.nn.modules.rnn.LSTM'>.\n",
            "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool1d'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
            "Flops: 77364082432.00\n",
            "MLOPS: 186.58\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-f0d979b1a134>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  'label': torch.tensor(self.label_list[item])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 17 step: 0/42\n",
            "epoch: 17 step: 4/42\n",
            "epoch: 17 step: 8/42\n",
            "epoch: 17 step: 12/42\n",
            "epoch: 17 step: 16/42\n",
            "epoch: 17 step: 20/42\n",
            "epoch: 17 step: 24/42\n",
            "epoch: 17 step: 28/42\n",
            "epoch: 17 step: 32/42\n",
            "epoch: 17 step: 36/42\n",
            "epoch: 17 step: 40/42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "<ipython-input-1-f0d979b1a134>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  'label': torch.tensor(self.label_list[item])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test\n",
            "epoch: 17 train_loss: 0.05180828512779304 train_acc: 82.43% train_f1: 73.88%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "<ipython-input-1-f0d979b1a134>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  'label': torch.tensor(self.label_list[item])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          val_loss: 0.05575442110950297 val_acc 77.76% val_f1: 66.52%\n",
            "TextRCNN AUC =  0.8487307598468213\n",
            "Specificity =  0.7953091684434968\n",
            "Sensitivity =  0.736318407960199\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.8756    0.7953    0.8335       469\n",
            "         1.0     0.6066    0.7363    0.6652       201\n",
            "\n",
            "    accuracy                         0.7776       670\n",
            "   macro avg     0.7411    0.7658    0.7493       670\n",
            "weighted avg     0.7949    0.7776    0.7830       670\n",
            "\n",
            "[INFO] Register count_lstm() for <class 'torch.nn.modules.rnn.LSTM'>.\n",
            "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool1d'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
            "Flops: 77364082432.00\n",
            "MLOPS: 184.57\n",
            "epoch: 18 step: 0/42\n",
            "epoch: 18 step: 4/42\n",
            "epoch: 18 step: 8/42\n",
            "epoch: 18 step: 12/42\n",
            "epoch: 18 step: 16/42\n",
            "epoch: 18 step: 20/42\n",
            "epoch: 18 step: 24/42\n",
            "epoch: 18 step: 28/42\n",
            "epoch: 18 step: 32/42\n",
            "epoch: 18 step: 36/42\n",
            "epoch: 18 step: 40/42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "<ipython-input-1-f0d979b1a134>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  'label': torch.tensor(self.label_list[item])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test\n",
            "epoch: 18 train_loss: 0.050389522863995465 train_acc: 81.16% train_f1: 73.35%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "<ipython-input-1-f0d979b1a134>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  'label': torch.tensor(self.label_list[item])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          val_loss: 0.05485193058848381 val_acc 77.46% val_f1: 67.53%\n",
            "TextRCNN AUC =  0.8514994324751508\n",
            "Specificity =  0.7718550106609808\n",
            "Sensitivity =  0.7810945273631841\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.8916    0.7719    0.8274       469\n",
            "         1.0     0.5947    0.7811    0.6753       201\n",
            "\n",
            "    accuracy                         0.7746       670\n",
            "   macro avg     0.7432    0.7765    0.7513       670\n",
            "weighted avg     0.8025    0.7746    0.7818       670\n",
            "\n",
            "[INFO] Register count_lstm() for <class 'torch.nn.modules.rnn.LSTM'>.\n",
            "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool1d'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
            "Flops: 77364082432.00\n",
            "MLOPS: 184.70\n",
            "epoch: 19 step: 0/42\n",
            "epoch: 19 step: 4/42\n",
            "epoch: 19 step: 8/42\n",
            "epoch: 19 step: 12/42\n",
            "epoch: 19 step: 16/42\n",
            "epoch: 19 step: 20/42\n",
            "epoch: 19 step: 24/42\n",
            "epoch: 19 step: 28/42\n",
            "epoch: 19 step: 32/42\n",
            "epoch: 19 step: 36/42\n",
            "epoch: 19 step: 40/42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "<ipython-input-1-f0d979b1a134>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  'label': torch.tensor(self.label_list[item])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test\n",
            "epoch: 19 train_loss: 0.04819513156655289 train_acc: 82.72% train_f1: 73.94%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "<ipython-input-1-f0d979b1a134>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  'label': torch.tensor(self.label_list[item])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          val_loss: 0.0537016246129166 val_acc 79.40% val_f1: 68.78%\n",
            "TextRCNN AUC =  0.8504280304235752\n",
            "Specificity =  0.8102345415778252\n",
            "Sensitivity =  0.7562189054726368\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.8858    0.8102    0.8463       469\n",
            "         1.0     0.6307    0.7562    0.6878       201\n",
            "\n",
            "    accuracy                         0.7940       670\n",
            "   macro avg     0.7582    0.7832    0.7671       670\n",
            "weighted avg     0.8093    0.7940    0.7988       670\n",
            "\n",
            "[INFO] Register count_lstm() for <class 'torch.nn.modules.rnn.LSTM'>.\n",
            "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool1d'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
            "Flops: 77364082432.00\n",
            "MLOPS: 187.06\n",
            "epoch: 20 step: 0/42\n",
            "epoch: 20 step: 4/42\n",
            "epoch: 20 step: 8/42\n",
            "epoch: 20 step: 12/42\n",
            "epoch: 20 step: 16/42\n",
            "epoch: 20 step: 20/42\n",
            "epoch: 20 step: 24/42\n",
            "epoch: 20 step: 28/42\n",
            "epoch: 20 step: 32/42\n",
            "epoch: 20 step: 36/42\n",
            "epoch: 20 step: 40/42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test\n",
            "epoch: 20 train_loss: 0.046316213107534816 train_acc: 83.43% train_f1: 73.48%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-f0d979b1a134>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  'label': torch.tensor(self.label_list[item])\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "<ipython-input-1-f0d979b1a134>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  'label': torch.tensor(self.label_list[item])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          val_loss: 0.05324819954958829 val_acc 79.25% val_f1: 67.45%\n",
            "TextRCNN AUC =  0.8484019136725753\n",
            "Specificity =  0.8251599147121536\n",
            "Sensitivity =  0.7164179104477612\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.8716    0.8252    0.8478       469\n",
            "         1.0     0.6372    0.7164    0.6745       201\n",
            "\n",
            "    accuracy                         0.7925       670\n",
            "   macro avg     0.7544    0.7708    0.7611       670\n",
            "weighted avg     0.8013    0.7925    0.7958       670\n",
            "\n",
            "[INFO] Register count_lstm() for <class 'torch.nn.modules.rnn.LSTM'>.\n",
            "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool1d'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
            "Flops: 77364082432.00\n",
            "MLOPS: 186.47\n",
            "epoch: 21 step: 0/42\n",
            "epoch: 21 step: 4/42\n",
            "epoch: 21 step: 8/42\n",
            "epoch: 21 step: 12/42\n",
            "epoch: 21 step: 16/42\n",
            "epoch: 21 step: 20/42\n",
            "epoch: 21 step: 24/42\n",
            "epoch: 21 step: 28/42\n",
            "epoch: 21 step: 32/42\n",
            "epoch: 21 step: 36/42\n",
            "epoch: 21 step: 40/42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "<ipython-input-1-f0d979b1a134>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  'label': torch.tensor(self.label_list[item])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test\n",
            "epoch: 21 train_loss: 0.045973449324568115 train_acc: 78.96% train_f1: 72.24%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "<ipython-input-1-f0d979b1a134>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  'label': torch.tensor(self.label_list[item])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          val_loss: 0.05330983176827431 val_acc 75.37% val_f1: 66.80%\n",
            "TextRCNN AUC =  0.8511599783598001\n",
            "Specificity =  0.7228144989339019\n",
            "Sensitivity =  0.8258706467661692\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.9064    0.7228    0.8043       469\n",
            "         1.0     0.5608    0.8259    0.6680       201\n",
            "\n",
            "    accuracy                         0.7537       670\n",
            "   macro avg     0.7336    0.7743    0.7361       670\n",
            "weighted avg     0.8027    0.7537    0.7634       670\n",
            "\n",
            "[INFO] Register count_lstm() for <class 'torch.nn.modules.rnn.LSTM'>.\n",
            "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool1d'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
            "Flops: 77364082432.00\n",
            "MLOPS: 186.75\n",
            "epoch: 22 step: 0/42\n",
            "epoch: 22 step: 4/42\n",
            "epoch: 22 step: 8/42\n",
            "epoch: 22 step: 12/42\n",
            "epoch: 22 step: 16/42\n",
            "epoch: 22 step: 20/42\n",
            "epoch: 22 step: 24/42\n",
            "epoch: 22 step: 28/42\n",
            "epoch: 22 step: 32/42\n",
            "epoch: 22 step: 36/42\n",
            "epoch: 22 step: 40/42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "<ipython-input-1-f0d979b1a134>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  'label': torch.tensor(self.label_list[item])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test\n",
            "epoch: 22 train_loss: 0.04372625789117245 train_acc: 81.19% train_f1: 73.89%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "<ipython-input-1-f0d979b1a134>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  'label': torch.tensor(self.label_list[item])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          val_loss: 0.052810935472900215 val_acc 76.72% val_f1: 67.77%\n",
            "TextRCNN AUC =  0.847648749854141\n",
            "Specificity =  0.746268656716418\n",
            "Sensitivity =  0.8159203980099502\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.9044    0.7463    0.8178       469\n",
            "         1.0     0.5795    0.8159    0.6777       201\n",
            "\n",
            "    accuracy                         0.7672       670\n",
            "   macro avg     0.7419    0.7811    0.7477       670\n",
            "weighted avg     0.8069    0.7672    0.7757       670\n",
            "\n",
            "[INFO] Register count_lstm() for <class 'torch.nn.modules.rnn.LSTM'>.\n",
            "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool1d'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
            "Flops: 77364082432.00\n",
            "MLOPS: 183.79\n",
            "epoch: 23 step: 0/42\n",
            "epoch: 23 step: 4/42\n",
            "epoch: 23 step: 8/42\n",
            "epoch: 23 step: 12/42\n",
            "epoch: 23 step: 16/42\n",
            "epoch: 23 step: 20/42\n",
            "epoch: 23 step: 24/42\n",
            "epoch: 23 step: 28/42\n",
            "epoch: 23 step: 32/42\n",
            "epoch: 23 step: 36/42\n",
            "epoch: 23 step: 40/42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "<ipython-input-1-f0d979b1a134>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  'label': torch.tensor(self.label_list[item])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test\n",
            "epoch: 23 train_loss: 0.04156030514942748 train_acc: 82.95% train_f1: 74.96%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "<ipython-input-1-f0d979b1a134>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  'label': torch.tensor(self.label_list[item])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          val_loss: 0.05194129591638392 val_acc 79.25% val_f1: 69.04%\n",
            "TextRCNN AUC =  0.8504492463057844\n",
            "Specificity =  0.8017057569296375\n",
            "Sensitivity =  0.7711442786069652\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.8910    0.8017    0.8440       469\n",
            "         1.0     0.6250    0.7711    0.6904       201\n",
            "\n",
            "    accuracy                         0.7925       670\n",
            "   macro avg     0.7580    0.7864    0.7672       670\n",
            "weighted avg     0.8112    0.7925    0.7979       670\n",
            "\n",
            "[INFO] Register count_lstm() for <class 'torch.nn.modules.rnn.LSTM'>.\n",
            "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool1d'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
            "Flops: 77364082432.00\n",
            "MLOPS: 185.92\n",
            "epoch: 24 step: 0/42\n",
            "epoch: 24 step: 4/42\n",
            "epoch: 24 step: 8/42\n",
            "epoch: 24 step: 12/42\n",
            "epoch: 24 step: 16/42\n",
            "epoch: 24 step: 20/42\n",
            "epoch: 24 step: 24/42\n",
            "epoch: 24 step: 28/42\n",
            "epoch: 24 step: 32/42\n",
            "epoch: 24 step: 36/42\n",
            "epoch: 24 step: 40/42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test\n",
            "epoch: 24 train_loss: 0.04034851376144659 train_acc: 83.43% train_f1: 76.18%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-f0d979b1a134>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  'label': torch.tensor(self.label_list[item])\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "<ipython-input-1-f0d979b1a134>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  'label': torch.tensor(self.label_list[item])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          val_loss: 0.05114357410506769 val_acc 79.55% val_f1: 70.28%\n",
            "TextRCNN AUC =  0.8570579936140194\n",
            "Specificity =  0.7910447761194029\n",
            "Sensitivity =  0.8059701492537313\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.9049    0.7910    0.8441       469\n",
            "         1.0     0.6231    0.8060    0.7028       201\n",
            "\n",
            "    accuracy                         0.7955       670\n",
            "   macro avg     0.7640    0.7985    0.7735       670\n",
            "weighted avg     0.8203    0.7955    0.8017       670\n",
            "\n",
            "[INFO] Register count_lstm() for <class 'torch.nn.modules.rnn.LSTM'>.\n",
            "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool1d'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
            "Flops: 77364082432.00\n",
            "MLOPS: 187.06\n",
            "epoch: 25 step: 0/42\n",
            "epoch: 25 step: 4/42\n",
            "epoch: 25 step: 8/42\n",
            "epoch: 25 step: 12/42\n",
            "epoch: 25 step: 16/42\n",
            "epoch: 25 step: 20/42\n",
            "epoch: 25 step: 24/42\n",
            "epoch: 25 step: 28/42\n",
            "epoch: 25 step: 32/42\n",
            "epoch: 25 step: 36/42\n",
            "epoch: 25 step: 40/42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "<ipython-input-1-f0d979b1a134>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  'label': torch.tensor(self.label_list[item])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test\n",
            "epoch: 25 train_loss: 0.03877056917796532 train_acc: 84.18% train_f1: 76.81%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "<ipython-input-1-f0d979b1a134>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  'label': torch.tensor(self.label_list[item])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          val_loss: 0.051236990839242935 val_acc 79.85% val_f1: 70.07%\n",
            "TextRCNN AUC =  0.8568352268508206\n",
            "Specificity =  0.8038379530916845\n",
            "Sensitivity =  0.7860696517412935\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.8976    0.8038    0.8481       469\n",
            "         1.0     0.6320    0.7861    0.7007       201\n",
            "\n",
            "    accuracy                         0.7985       670\n",
            "   macro avg     0.7648    0.7950    0.7744       670\n",
            "weighted avg     0.8179    0.7985    0.8039       670\n",
            "\n",
            "[INFO] Register count_lstm() for <class 'torch.nn.modules.rnn.LSTM'>.\n",
            "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool1d'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
            "Flops: 77364082432.00\n",
            "MLOPS: 189.14\n",
            "epoch: 26 step: 0/42\n",
            "epoch: 26 step: 4/42\n",
            "epoch: 26 step: 8/42\n",
            "epoch: 26 step: 12/42\n",
            "epoch: 26 step: 16/42\n",
            "epoch: 26 step: 20/42\n",
            "epoch: 26 step: 24/42\n",
            "epoch: 26 step: 28/42\n",
            "epoch: 26 step: 32/42\n",
            "epoch: 26 step: 36/42\n",
            "epoch: 26 step: 40/42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "<ipython-input-1-f0d979b1a134>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  'label': torch.tensor(self.label_list[item])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test\n",
            "epoch: 26 train_loss: 0.038514927650491394 train_acc: 87.05% train_f1: 78.35%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "<ipython-input-1-f0d979b1a134>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  'label': torch.tensor(self.label_list[item])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          val_loss: 0.0520608862015334 val_acc 81.19% val_f1: 69.12%\n",
            "TextRCNN AUC =  0.8597205868313018\n",
            "Specificity =  0.8592750533049041\n",
            "Sensitivity =  0.7014925373134329\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.8704    0.8593    0.8648       469\n",
            "         1.0     0.6812    0.7015    0.6912       201\n",
            "\n",
            "    accuracy                         0.8119       670\n",
            "   macro avg     0.7758    0.7804    0.7780       670\n",
            "weighted avg     0.8136    0.8119    0.8127       670\n",
            "\n",
            "[INFO] Register count_lstm() for <class 'torch.nn.modules.rnn.LSTM'>.\n",
            "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool1d'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
            "Flops: 77364082432.00\n",
            "MLOPS: 184.92\n",
            "epoch: 27 step: 0/42\n",
            "epoch: 27 step: 4/42\n",
            "epoch: 27 step: 8/42\n",
            "epoch: 27 step: 12/42\n",
            "epoch: 27 step: 16/42\n",
            "epoch: 27 step: 20/42\n",
            "epoch: 27 step: 24/42\n",
            "epoch: 27 step: 28/42\n",
            "epoch: 27 step: 32/42\n",
            "epoch: 27 step: 36/42\n",
            "epoch: 27 step: 40/42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "<ipython-input-1-f0d979b1a134>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  'label': torch.tensor(self.label_list[item])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test\n",
            "epoch: 27 train_loss: 0.03720829250024898 train_acc: 82.50% train_f1: 75.69%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "<ipython-input-1-f0d979b1a134>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  'label': torch.tensor(self.label_list[item])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          val_loss: 0.052302700552073395 val_acc 77.46% val_f1: 68.34%\n",
            "TextRCNN AUC =  0.8583733783110036\n",
            "Specificity =  0.7590618336886994\n",
            "Sensitivity =  0.8109452736318408\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.9036    0.7591    0.8250       469\n",
            "         1.0     0.5906    0.8109    0.6834       201\n",
            "\n",
            "    accuracy                         0.7746       670\n",
            "   macro avg     0.7471    0.7850    0.7542       670\n",
            "weighted avg     0.8097    0.7746    0.7826       670\n",
            "\n",
            "[INFO] Register count_lstm() for <class 'torch.nn.modules.rnn.LSTM'>.\n",
            "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool1d'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
            "Flops: 77364082432.00\n",
            "MLOPS: 186.43\n",
            "epoch: 28 step: 0/42\n",
            "epoch: 28 step: 4/42\n",
            "epoch: 28 step: 8/42\n",
            "epoch: 28 step: 12/42\n",
            "epoch: 28 step: 16/42\n",
            "epoch: 28 step: 20/42\n",
            "epoch: 28 step: 24/42\n",
            "epoch: 28 step: 28/42\n",
            "epoch: 28 step: 32/42\n",
            "epoch: 28 step: 36/42\n",
            "epoch: 28 step: 40/42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test\n",
            "epoch: 28 train_loss: 0.03674527843083654 train_acc: 81.98% train_f1: 75.52%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-f0d979b1a134>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  'label': torch.tensor(self.label_list[item])\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "<ipython-input-1-f0d979b1a134>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  'label': torch.tensor(self.label_list[item])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          val_loss: 0.05341758748347109 val_acc 76.42% val_f1: 67.76%\n",
            "TextRCNN AUC =  0.8586704006619356\n",
            "Specificity =  0.7377398720682303\n",
            "Sensitivity =  0.8258706467661692\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.9081    0.7377    0.8141       469\n",
            "         1.0     0.5744    0.8259    0.6776       201\n",
            "\n",
            "    accuracy                         0.7642       670\n",
            "   macro avg     0.7413    0.7818    0.7458       670\n",
            "weighted avg     0.8080    0.7642    0.7731       670\n",
            "\n",
            "[INFO] Register count_lstm() for <class 'torch.nn.modules.rnn.LSTM'>.\n",
            "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool1d'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
            "Flops: 77364082432.00\n",
            "MLOPS: 186.85\n",
            "epoch: 29 step: 0/42\n",
            "epoch: 29 step: 4/42\n",
            "epoch: 29 step: 8/42\n",
            "epoch: 29 step: 12/42\n",
            "epoch: 29 step: 16/42\n",
            "epoch: 29 step: 20/42\n",
            "epoch: 29 step: 24/42\n",
            "epoch: 29 step: 28/42\n",
            "epoch: 29 step: 32/42\n",
            "epoch: 29 step: 36/42\n",
            "epoch: 29 step: 40/42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "<ipython-input-1-f0d979b1a134>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  'label': torch.tensor(self.label_list[item])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test\n",
            "epoch: 29 train_loss: 0.03400764982437804 train_acc: 85.45% train_f1: 78.85%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          val_loss: 0.05150390788912773 val_acc 79.10% val_f1: 69.70%\n",
            "TextRCNN AUC =  0.8616512321123594\n",
            "Specificity =  0.7867803837953091\n",
            "Sensitivity =  0.8009950248756219\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.9022    0.7868    0.8405       469\n",
            "         1.0     0.6169    0.8010    0.6970       201\n",
            "\n",
            "    accuracy                         0.7910       670\n",
            "   macro avg     0.7595    0.7939    0.7688       670\n",
            "weighted avg     0.8166    0.7910    0.7975       670\n",
            "\n",
            "[INFO] Register count_lstm() for <class 'torch.nn.modules.rnn.LSTM'>.\n",
            "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool1d'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
            "Flops: 77364082432.00\n",
            "MLOPS: 187.06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-f0d979b1a134>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  'label': torch.tensor(self.label_list[item])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 30 step: 0/42\n",
            "epoch: 30 step: 4/42\n",
            "epoch: 30 step: 8/42\n",
            "epoch: 30 step: 12/42\n",
            "epoch: 30 step: 16/42\n",
            "epoch: 30 step: 20/42\n",
            "epoch: 30 step: 24/42\n",
            "epoch: 30 step: 28/42\n",
            "epoch: 30 step: 32/42\n",
            "epoch: 30 step: 36/42\n",
            "epoch: 30 step: 40/42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "<ipython-input-1-f0d979b1a134>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  'label': torch.tensor(self.label_list[item])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test\n",
            "epoch: 30 train_loss: 0.032971274063345934 train_acc: 85.78% train_f1: 79.30%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  array = numpy.asarray(array, order=order, dtype=dtype)\n",
            "<ipython-input-1-f0d979b1a134>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  'label': torch.tensor(self.label_list[item])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          val_loss: 0.051861222833395004 val_acc 78.96% val_f1: 69.41%\n",
            "TextRCNN AUC =  0.8615027209368935\n",
            "Specificity =  0.7867803837953091\n",
            "Sensitivity =  0.7960199004975125\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.9000    0.7868    0.8396       469\n",
            "         1.0     0.6154    0.7960    0.6941       201\n",
            "\n",
            "    accuracy                         0.7896       670\n",
            "   macro avg     0.7577    0.7914    0.7669       670\n",
            "weighted avg     0.8146    0.7896    0.7960       670\n",
            "\n",
            "[INFO] Register count_lstm() for <class 'torch.nn.modules.rnn.LSTM'>.\n",
            "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool1d'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
            "Flops: 77364082432.00\n",
            "MLOPS: 184.65\n",
            "epoch: 31 step: 0/42\n",
            "epoch: 31 step: 4/42\n",
            "epoch: 31 step: 8/42\n",
            "epoch: 31 step: 12/42\n",
            "epoch: 31 step: 16/42\n",
            "epoch: 31 step: 20/42\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-d361f939f5d0>\u001b[0m in \u001b[0;36m<cell line: 222>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/neckpain_model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-7-d361f939f5d0>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjournal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabstruct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m             \u001b[0;31m# print(logits[:, 1].unsqueeze(1))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;31m# print(label)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-4d2e9bb82cc1>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, journal, title, abstruct)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mabstruct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabstruct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0membed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabstruct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0;31m# print(\"embed: \",embed.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m# print(\"out: \", out.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    810\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 812\u001b[0;31m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0m\u001b[1;32m    813\u001b[0m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[1;32m    814\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9gyb-HEW_PrD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}